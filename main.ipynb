{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:11.691280Z",
     "start_time": "2023-11-29T08:47:11.688723Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:11.883441Z",
     "start_time": "2023-11-29T08:47:11.880648Z"
    }
   },
   "id": "369c10e0a806ed9"
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "# Directories of the dataset \n",
    "train_original_directory = os.path.join(\"Data\",\"Original_data\",\"train_essays.csv\")\n",
    "test_original_directory = os.path.join(\"Data\",\"Original_data\",\"test_essays.csv\")\n",
    "train_original_prompts_directory = os.path.join(\"Data\",\"Original_data\",\"train_prompts.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:12.027536Z",
     "start_time": "2023-11-29T08:47:12.024574Z"
    }
   },
   "id": "8fedbfa28d2fc8d0"
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "train_original_df = pd.read_csv(train_original_directory)\n",
    "test_original_df = pd.read_csv(test_original_directory)\n",
    "train_original_prompts_df = pd.read_csv(train_original_prompts_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:12.196014Z",
     "start_time": "2023-11-29T08:47:12.157996Z"
    }
   },
   "id": "bdd3d95a8ed5dc10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Goals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba0b400657e5dc3a"
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "         id  prompt_id                                               text  \\\n0  0059830c          0  Cars. Cars have been around since they became ...   \n1  005db917          0  Transportation is a large necessity in most co...   \n2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n3  00940276          0  How often do you ride in a car? Do you drive a...   \n4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n\n   generated  \n0          0  \n1          0  \n2          0  \n3          0  \n4          0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated -> 0 means written by humans \n",
    "train_original_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:12.467158Z",
     "start_time": "2023-11-29T08:47:12.464417Z"
    }
   },
   "id": "40147f8929ad1d0e"
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "# Data Cleaning should be independent from the dataLoader (Usefull if we plan to use machine learning model as well\n",
    "# Embedding should be injected into the dataloader class (Makes embedding indepent from the dataloading part \n",
    "# At the moment we don't care about the prompt text but might be usefull in future processing "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:12.642125Z",
     "start_time": "2023-11-29T08:47:12.637210Z"
    }
   },
   "id": "9fd429f46234c237"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Aggregation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7336cd3d687175cc"
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "    \"\"\"\n",
    "    This class is just to clean the dataset and the output of this class should be a cleaned dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,values:list = None):\n",
    "        self.__paths : list[str] = []\n",
    "        \n",
    "        if values:\n",
    "            self.__paths = [*values]\n",
    "        \n",
    "    @property\n",
    "    def paths(self):\n",
    "        return self.__paths\n",
    "    \n",
    "    @paths.setter\n",
    "    def paths(self,value):\n",
    "        self.paths.append(value)\n",
    "        \n",
    "    def clean(self):\n",
    "        final_df = None\n",
    "        with tqdm(total=len(self.paths), desc=\"Processing CSV files\") as pbar:\n",
    "            for path in self.paths:\n",
    "                temp_df = pd.read_csv(path)\n",
    "                # if(path.split('/') == \"Original\"):\n",
    "                temp_df = self.cleanOriginal(temp_df)\n",
    "        \n",
    "                if final_df is None:\n",
    "                    final_df = temp_df\n",
    "                else:\n",
    "                    final_df = pd.concat([final_df, temp_df])\n",
    "        \n",
    "                pbar.update(1)\n",
    "                pbar.set_description(f\"Processing: {path.split()[-1]}\")\n",
    "        return final_df\n",
    "            \n",
    "    def cleanOriginal(self,temp_df):\n",
    "        return temp_df[[\"text\",\"generated\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:12.994700Z",
     "start_time": "2023-11-29T08:47:12.988749Z"
    }
   },
   "id": "94ab24a2c1fc3f62"
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "# get all the csv files\n",
    "search_pattern = os.path.join(\"Data\", '**', '*.csv')\n",
    "csv_paths = glob.glob(search_pattern, recursive=True)\n",
    "# Remove the test file \n",
    "csv_paths.remove(test_original_directory)\n",
    "csv_paths.remove(train_original_prompts_directory)\n",
    "csv_paths.remove(os.path.join(\"Data\",\"Original_data\",\"sample_submission.csv\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:13.178842Z",
     "start_time": "2023-11-29T08:47:13.175042Z"
    }
   },
   "id": "838110d584229b6b"
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "customDataset = CreateDataset(csv_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:13.340977Z",
     "start_time": "2023-11-29T08:47:13.338870Z"
    }
   },
   "id": "96912f4345f7b987"
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Data/daigt-data-llama-70b-and-falcon180b/ai_generated_train_essays_gpt-4.csv: 100%|██████████| 19/19 [00:00<00:00, 73.88it/s]             \n"
     ]
    }
   ],
   "source": [
    "train_complete_df = customDataset.clean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:13.768300Z",
     "start_time": "2023-11-29T08:47:13.497138Z"
    }
   },
   "id": "6eaf5a748dbff067"
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "generated\n1    6303\n0    1375\nName: count, dtype: int64"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_complete_df[\"generated\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:15.166880Z",
     "start_time": "2023-11-29T08:47:15.156210Z"
    }
   },
   "id": "9e8521b8b50a0324"
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "def split_train_by_senctence_window(df,is_sentence = True,k_sentences = 0 , window_size_= 100 , stride = 50):\n",
    "    if is_sentence:\n",
    "        # based on the sentences \n",
    "        k = 0\n",
    "        temp_df = df[\"text\"].apply(lambda x: re.findall(r'[^.!?]+[.!?]', x))\n",
    "        temp_df = temp_df.apply(lambda x : [s.replace(\"\\n\",\"\").strip() for s in x if s != \"\"])\n",
    "        # combine the sentences \n",
    "        if k != 0:\n",
    "            temp_df = temp_df.apply(lambda x : [\" \".join(x[i:i+1+k]) for i in range(len(x)-k)])\n",
    "        columns = list(df.columns)\n",
    "        columns.remove('text')\n",
    "        temp_df = pd.concat([temp_df,df[columns]],axis = 1)\n",
    "        temp_df = temp_df.explode(\"text\")\n",
    "        temp_df.reset_index(inplace = True,drop = True)\n",
    "    else:\n",
    "        # based on the window\n",
    "        window_size = 100\n",
    "        stride = 50\n",
    "        temp_df = df[\"text\"].apply(lambda x : [x[i:i+1+window_size] for i in range(0,len(x)-window_size,stride)])\n",
    "        columns = list(df.columns)\n",
    "        columns.remove('text')\n",
    "        temp_df = pd.concat([temp_df,df[columns]],axis = 1)\n",
    "        temp_df = temp_df.explode(\"text\")\n",
    "        temp_df.reset_index(inplace = True,drop = True)\n",
    "    return temp_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:16.095449Z",
     "start_time": "2023-11-29T08:47:16.084941Z"
    }
   },
   "id": "e0e25986be6e44bf"
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "# Split the dataset based on the counts of 0 and 1\n",
    "stratify_column = 'generated'\n",
    "train_complete_df, validation_complete_df = train_test_split(train_complete_df, test_size=0.2, stratify=train_complete_df[stratify_column], random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:25.328841Z",
     "start_time": "2023-11-29T08:47:25.315048Z"
    }
   },
   "id": "4d87508320c4ba35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9f9904a5ae50961"
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using pretrained model tokenizer \n",
    "model_name = \"microsoft/deberta-v3-xsmall\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:52:13.252604Z",
     "start_time": "2023-11-29T08:52:12.520139Z"
    }
   },
   "id": "cdc6769119fdb705"
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "data": {
      "text/plain": "128001"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:26.734848Z",
     "start_time": "2023-11-29T08:47:26.726540Z"
    }
   },
   "id": "c7ec72e3c7665a5b"
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "# Create a DataLoader class \n",
    "class DetectionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,Tokenizer = None,train = True,max_length = 100):\n",
    "        self.tokenizer = Tokenizer\n",
    "        self.train = train\n",
    "        self.df = df\n",
    "        self.max_length = max_length\n",
    "        self.padded_token = 0 if self.tokenizer is None else self.tokenizer.convert_tokens_to_ids(self.tokenizer.pad_token)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        :return: text containing the indexes in numpy array / list\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            if self.tokenizer is None: \n",
    "                return {\"text\" : self.df.iloc[item][\"text\"],\"score\" : self.df.iloc[item][\"generated\"]}\n",
    "            else:\n",
    "                vectorized_text = self.vectorize(self.df.iloc[item][\"text\"])\n",
    "                return {\"text\" : vectorized_text,\"score\" : self.df.iloc[item][\"generated\"]}\n",
    "        else:\n",
    "            if self.tokenizer is None:\n",
    "                return {\"text\" : self.df.iloc[item][\"text\"]}\n",
    "            else:\n",
    "                vectorized_text = self.vectorize(self.df.iloc[item][\"text\"])\n",
    "                return {\"text\" : vectorized_text}\n",
    "        \n",
    "    def pad(self,vector,length):\n",
    "        result = np.ones(length) * self.padded_token\n",
    "        result[:len(vector)] = vector\n",
    "        return result\n",
    "    \n",
    "    def commonCollate(self,batch):\n",
    "        max_length = max([len(item['text']) for item in batch])\n",
    "        texts = [self.pad(item['text'],max_length) for item in batch]\n",
    "        return texts\n",
    "        \n",
    "    \n",
    "    def collate(self,batch):\n",
    "        texts = self.commonCollate(batch)\n",
    "        scores = [item['score'] for item in batch]    \n",
    "        return {'text': torch.LongTensor(texts), \n",
    "                'score': torch.tensor(scores, dtype=torch.float32)}\n",
    "    \n",
    "    def test_collate(self,batch):\n",
    "        texts = self.commonCollate(batch)\n",
    "        return {'text' : torch.LongTensor(texts)}\n",
    "    \n",
    "    def vectorize(self,text):\n",
    "        return self.tokenizer(text)[\"input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:47:27.646529Z",
     "start_time": "2023-11-29T08:47:27.639730Z"
    }
   },
   "id": "699912aecea29d4"
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "train_detectionDataset = DetectionDataset(train_complete_df,tokenizer)\n",
    "validation_detectionDataset = DetectionDataset(validation_complete_df,tokenizer)\n",
    "test_detectionDataset = DetectionDataset(test_original_df,tokenizer, train = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:48:00.091989Z",
     "start_time": "2023-11-29T08:48:00.090494Z"
    }
   },
   "id": "251efd8d0435def9"
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_detectionDataset, batch_size=32, shuffle=True, collate_fn=train_detectionDataset.collate)\n",
    "validation_dataloader = DataLoader(validation_detectionDataset, batch_size=32, shuffle=True, collate_fn=validation_detectionDataset.collate)\n",
    "test_dataloader = DataLoader(test_detectionDataset, batch_size=len(test_detectionDataset), shuffle=False, collate_fn=test_detectionDataset.test_collate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T08:49:11.429096Z",
     "start_time": "2023-11-29T08:49:11.427305Z"
    }
   },
   "id": "6c03ad8ebbb485ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "143a9909d49009dd"
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "# source : https://d2l.ai/chapter_attention-mechanisms-and-transformers/multihead-attention.html\n",
    "class PositionalEncoding(nn.Module):  #@save\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=3000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T09:01:18.315976Z",
     "start_time": "2023-11-29T09:01:18.314222Z"
    }
   },
   "id": "5cc96eb36ea7c617"
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,n_layers = 6,nhead = 4,dim_feedforward = 512,dropout = 0.5,activation = \"gelu\"):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.position_encoding = PositionalEncoding(embedding_size,dropout)\n",
    "        self.Encoder = nn.TransformerEncoderLayer(\n",
    "            d_model = embedding_size,\n",
    "            nhead = nhead,\n",
    "            dim_feedforward= dim_feedforward,\n",
    "            dropout = dropout,\n",
    "            activation = activation,\n",
    "            batch_first= True,\n",
    "            norm_first= True,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.Encoder, num_layers=n_layers)\n",
    "        self.output = nn.Linear(embedding_size,1,bias = True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x) # B x T X C\n",
    "        x = self.position_encoding(x) # B x T x C with position information added \n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T09:01:18.644133Z",
     "start_time": "2023-11-29T09:01:18.634882Z"
    }
   },
   "id": "a36c41bffbb4a890"
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(len(tokenizer.get_vocab()),300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T09:01:19.567374Z",
     "start_time": "2023-11-29T09:01:19.072866Z"
    }
   },
   "id": "46025c18aea17ace"
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "def train_batch(X,y,model,loss_function,optimizer):\n",
    "    \"\"\"\n",
    "    :return: (loss , accuracy)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    predicitons = model(X) # Batch * Time stamp * 1\n",
    "    predicitons = torch.mean(predicitons,1)\n",
    "    print(predicitons.shape)\n",
    "    print(y.shape)\n",
    "    batch_loss = loss_function(predicitons,y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item() * X.shape[0],accuray(y,predicitons)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def Inference(X,y,model,loss_function):\n",
    "    predictions = model(X)\n",
    "    loss = loss_function(predictions,y)\n",
    "    accuracy = torch.sum(torch.argmax(predictions) == y)\n",
    "    return loss.item() * X.shape[0],accuracy.item()\n",
    "\n",
    "def train(train_loader,test_loader,model,loss_function,optimizer):\n",
    "    \"\"\"\n",
    "    :return: (plot nothing to return )\n",
    "    \"\"\"\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    with tqdm(total=EPOCHS, desc='Training') as epoch_bar:\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss_epoch,train_accuracy_epoch = [],[]\n",
    "            test_loss_epoch, test_accuracy_epoch = [],[]\n",
    "            for batch in train_loader:\n",
    "                X = batch[\"text\"]\n",
    "                y = batch[\"score\"]\n",
    "                loss,accuray = train_batch(X,y,model,loss_function,optimizer)\n",
    "                train_loss_epoch.append(loss)\n",
    "                train_accuracy_epoch.append(accuray)\n",
    "                \n",
    "                #TODO : Remove\n",
    "                break\n",
    "                #TODO : Remove\n",
    "                \n",
    "\n",
    "\n",
    "            for X,y in test_loader:\n",
    "                loss,accuray = Inference(X,y,model,loss_function)\n",
    "                test_loss_epoch.append(loss)\n",
    "                test_accuracy_epoch.append(accuray)\n",
    "\n",
    "                #TODO : Remove\n",
    "                break\n",
    "                #TODO : Remove\n",
    "\n",
    "            train_losses.append(np.sum(np.array(train_loss_epoch)) / len(train_loader.dataset)  )\n",
    "            train_accuracies.append(np.sum(np.array(train_accuracy_epoch)) / len(train_loader.dataset) )\n",
    "            test_losses.append(np.sum(np.array(test_loss_epoch))/ len(test_loader.dataset) )\n",
    "            test_accuracies.append(np.sum(np.array(test_accuracy_epoch)) / len(test_loader.dataset) )\n",
    "\n",
    "            epoch_bar.set_postfix(\n",
    "                loss=f'{np.sum(np.array(train_loss_epoch)) / len(train_loader.dataset):.4f}',\n",
    "                accuracy=f'{100 * np.sum(np.array(train_accuracy_epoch)) / len(train_loader.dataset):.2f}%'\n",
    "            )\n",
    "            epoch_bar.set_description(f'Epoch {epoch + 1}')\n",
    "            epoch_bar.update(1)\n",
    "    \n",
    "\n",
    "def accuray(y_true,y_predictions):\n",
    "    \"\"\"\n",
    "    :return: accuracy\n",
    "    \"\"\"\n",
    "    final_predicitons = torch.argmax(y_predictions,dim = 1)\n",
    "    total_accuracy = torch.sum(y_true == final_predicitons)\n",
    "    return total_accuracy.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T09:08:53.841570Z",
     "start_time": "2023-11-29T09:08:53.823551Z"
    }
   },
   "id": "7fcf548fab871cf"
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(len(tokenizer.get_vocab()),300)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T09:08:54.851113Z",
     "start_time": "2023-11-29T09:08:54.350704Z"
    }
   },
   "id": "edea7fba9eedd695"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(train_dataloader,validation_dataloader,model,loss_function,optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-29T09:08:54.851812Z"
    }
   },
   "id": "35aeefe31755ffd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "48b2206640b41aae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
