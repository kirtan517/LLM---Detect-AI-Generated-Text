{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:27.619045Z",
     "start_time": "2023-11-29T12:15:25.871393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mkananikirtan73\u001B[0m (\u001B[33mfirs\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/kirtankanani/Desktop/Fall-2023/Syde-599/Project/wandb/run-20231129_071528-d1ywl8zl</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/firs/FinalProjectSYDE599/runs/d1ywl8zl' target=\"_blank\">sunny-snow-4</a></strong> to <a href='https://wandb.ai/firs/FinalProjectSYDE599' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/firs/FinalProjectSYDE599' target=\"_blank\">https://wandb.ai/firs/FinalProjectSYDE599</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/firs/FinalProjectSYDE599/runs/d1ywl8zl' target=\"_blank\">https://wandb.ai/firs/FinalProjectSYDE599/runs/d1ywl8zl</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/firs/FinalProjectSYDE599/runs/d1ywl8zl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x29d04e8d0>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "if not torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Wandb thing\n",
    "config={\n",
    "\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\" : BATCH_SIZE,\n",
    "}\n",
    "wandb.login()\n",
    "\n",
    "wandb.init(project=\"FinalProjectSYDE599\",config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:32.398035Z",
     "start_time": "2023-11-29T12:15:27.629780Z"
    }
   },
   "id": "8c8cc33c5d507ccd"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Directories of the dataset \n",
    "train_original_directory = os.path.join(\"Data\",\"Original_data\",\"train_essays.csv\")\n",
    "test_original_directory = os.path.join(\"Data\",\"Original_data\",\"test_essays.csv\")\n",
    "train_original_prompts_directory = os.path.join(\"Data\",\"Original_data\",\"train_prompts.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:32.398276Z",
     "start_time": "2023-11-29T12:15:32.393035Z"
    }
   },
   "id": "8fedbfa28d2fc8d0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_original_df = pd.read_csv(train_original_directory)\n",
    "test_original_df = pd.read_csv(test_original_directory)\n",
    "train_original_prompts_df = pd.read_csv(train_original_prompts_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:32.734085Z",
     "start_time": "2023-11-29T12:15:32.693298Z"
    }
   },
   "id": "bdd3d95a8ed5dc10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Goals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba0b400657e5dc3a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         id  prompt_id                                               text  \\\n0  0059830c          0  Cars. Cars have been around since they became ...   \n1  005db917          0  Transportation is a large necessity in most co...   \n2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n3  00940276          0  How often do you ride in a car? Do you drive a...   \n4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n\n   generated  \n0          0  \n1          0  \n2          0  \n3          0  \n4          0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated -> 0 means written by humans \n",
    "train_original_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:33.891753Z",
     "start_time": "2023-11-29T12:15:33.878Z"
    }
   },
   "id": "40147f8929ad1d0e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Data Cleaning should be independent from the dataLoader (Usefull if we plan to use machine learning model as well\n",
    "# Embedding should be injected into the dataloader class (Makes embedding indepent from the dataloading part \n",
    "# At the moment we don't care about the prompt text but might be usefull in future processing "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:34.489602Z",
     "start_time": "2023-11-29T12:15:34.482607Z"
    }
   },
   "id": "9fd429f46234c237"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Aggregation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7336cd3d687175cc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "    \"\"\"\n",
    "    This class is just to clean the dataset and the output of this class should be a cleaned dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,values:list = None):\n",
    "        self.__paths : list[str] = []\n",
    "        \n",
    "        if values:\n",
    "            self.__paths = [*values]\n",
    "        \n",
    "    @property\n",
    "    def paths(self):\n",
    "        return self.__paths\n",
    "    \n",
    "    @paths.setter\n",
    "    def paths(self,value):\n",
    "        self.paths.append(value)\n",
    "        \n",
    "    def clean(self):\n",
    "        final_df = None\n",
    "        with tqdm(total=len(self.paths), desc=\"Processing CSV files\") as pbar:\n",
    "            for path in self.paths:\n",
    "                temp_df = pd.read_csv(path)\n",
    "                # if(path.split('/') == \"Original\"):\n",
    "                temp_df = self.cleanOriginal(temp_df)\n",
    "        \n",
    "                if final_df is None:\n",
    "                    final_df = temp_df\n",
    "                else:\n",
    "                    final_df = pd.concat([final_df, temp_df])\n",
    "        \n",
    "                pbar.update(1)\n",
    "                pbar.set_description(f\"Processing: {path.split()[-1]}\")\n",
    "        return final_df\n",
    "            \n",
    "    def cleanOriginal(self,temp_df):\n",
    "        return temp_df[[\"text\",\"generated\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:35.777119Z",
     "start_time": "2023-11-29T12:15:35.767424Z"
    }
   },
   "id": "94ab24a2c1fc3f62"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# get all the csv files\n",
    "search_pattern = os.path.join(\"Data\", '**', '*.csv')\n",
    "csv_paths = glob.glob(search_pattern, recursive=True)\n",
    "# Remove the test file \n",
    "csv_paths.remove(test_original_directory)\n",
    "csv_paths.remove(train_original_prompts_directory)\n",
    "csv_paths.remove(os.path.join(\"Data\",\"Original_data\",\"sample_submission.csv\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:36.293847Z",
     "start_time": "2023-11-29T12:15:36.285535Z"
    }
   },
   "id": "838110d584229b6b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "customDataset = CreateDataset(csv_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:38.637840Z",
     "start_time": "2023-11-29T12:15:38.632635Z"
    }
   },
   "id": "96912f4345f7b987"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Data/daigt-data-llama-70b-and-falcon180b/ai_generated_train_essays_gpt-4.csv: 100%|██████████| 19/19 [00:00<00:00, 70.86it/s]             \n"
     ]
    }
   ],
   "source": [
    "train_complete_df = customDataset.clean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:43.393073Z",
     "start_time": "2023-11-29T12:15:43.107522Z"
    }
   },
   "id": "6eaf5a748dbff067"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "generated\n1    6303\n0    1375\nName: count, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_complete_df[\"generated\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:43.514632Z",
     "start_time": "2023-11-29T12:15:43.506755Z"
    }
   },
   "id": "9e8521b8b50a0324"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def split_train_by_senctence_window(df,is_sentence = True,k_sentences = 0 , window_size_= 100 , stride = 50):\n",
    "    if is_sentence:\n",
    "        # based on the sentences \n",
    "        k = 0\n",
    "        temp_df = df[\"text\"].apply(lambda x: re.findall(r'[^.!?]+[.!?]', x))\n",
    "        temp_df = temp_df.apply(lambda x : [s.replace(\"\\n\",\"\").strip() for s in x if s != \"\"])\n",
    "        # combine the sentences \n",
    "        if k != 0:\n",
    "            temp_df = temp_df.apply(lambda x : [\" \".join(x[i:i+1+k]) for i in range(len(x)-k)])\n",
    "        columns = list(df.columns)\n",
    "        columns.remove('text')\n",
    "        temp_df = pd.concat([temp_df,df[columns]],axis = 1)\n",
    "        temp_df = temp_df.explode(\"text\")\n",
    "        temp_df.reset_index(inplace = True,drop = True)\n",
    "    else:\n",
    "        # based on the window\n",
    "        window_size = 100\n",
    "        stride = 50\n",
    "        temp_df = df[\"text\"].apply(lambda x : [x[i:i+1+window_size] for i in range(0,len(x)-window_size,stride)])\n",
    "        columns = list(df.columns)\n",
    "        columns.remove('text')\n",
    "        temp_df = pd.concat([temp_df,df[columns]],axis = 1)\n",
    "        temp_df = temp_df.explode(\"text\")\n",
    "        temp_df.reset_index(inplace = True,drop = True)\n",
    "    return temp_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:44.024727Z",
     "start_time": "2023-11-29T12:15:44.013681Z"
    }
   },
   "id": "e0e25986be6e44bf"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Split the dataset based on the counts of 0 and 1\n",
    "stratify_column = 'generated'\n",
    "train_complete_df, validation_complete_df = train_test_split(train_complete_df, test_size=0.2, stratify=train_complete_df[stratify_column], random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:44.628972Z",
     "start_time": "2023-11-29T12:15:44.623942Z"
    }
   },
   "id": "4d87508320c4ba35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9f9904a5ae50961"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using pretrained model tokenizer \n",
    "model_name = \"microsoft/deberta-v3-xsmall\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:46.252675Z",
     "start_time": "2023-11-29T12:15:45.521029Z"
    }
   },
   "id": "cdc6769119fdb705"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "128001"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:46.405703Z",
     "start_time": "2023-11-29T12:15:46.362263Z"
    }
   },
   "id": "c7ec72e3c7665a5b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Create a DataLoader class \n",
    "class DetectionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,Tokenizer = None,train = True,max_length = 100):\n",
    "        self.tokenizer = Tokenizer\n",
    "        self.train = train\n",
    "        self.df = df\n",
    "        self.max_length = max_length\n",
    "        self.padded_token = 0 if self.tokenizer is None else self.tokenizer.convert_tokens_to_ids(self.tokenizer.pad_token)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        :return: text containing the indexes in numpy array / list\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            if self.tokenizer is None: \n",
    "                return {\"text\" : self.df.iloc[item][\"text\"],\"score\" : self.df.iloc[item][\"generated\"]}\n",
    "            else:\n",
    "                vectorized_text = self.vectorize(self.df.iloc[item][\"text\"])\n",
    "                return {\"text\" : vectorized_text,\"score\" : self.df.iloc[item][\"generated\"]}\n",
    "        else:\n",
    "            if self.tokenizer is None:\n",
    "                return {\"text\" : self.df.iloc[item][\"text\"]}\n",
    "            else:\n",
    "                vectorized_text = self.vectorize(self.df.iloc[item][\"text\"])\n",
    "                return {\"text\" : vectorized_text}\n",
    "        \n",
    "    def pad(self,vector,length):\n",
    "        result = np.ones(length) * self.padded_token\n",
    "        result[:len(vector)] = vector\n",
    "        return result\n",
    "    \n",
    "    def commonCollate(self,batch):\n",
    "        max_length = max([len(item['text']) for item in batch])\n",
    "        texts = [self.pad(item['text'],max_length) for item in batch]\n",
    "        return texts\n",
    "        \n",
    "    \n",
    "    def collate(self,batch):\n",
    "        texts = self.commonCollate(batch)\n",
    "        scores = [item['score'] for item in batch]    \n",
    "        return {'text': torch.LongTensor(texts), \n",
    "                'score': torch.tensor(scores, dtype=torch.float32)}\n",
    "    \n",
    "    def test_collate(self,batch):\n",
    "        texts = self.commonCollate(batch)\n",
    "        return {'text' : torch.LongTensor(texts)}\n",
    "    \n",
    "    def vectorize(self,text):\n",
    "        return self.tokenizer(text)[\"input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:47.039002Z",
     "start_time": "2023-11-29T12:15:47.032195Z"
    }
   },
   "id": "699912aecea29d4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train_detectionDataset = DetectionDataset(train_complete_df,tokenizer)\n",
    "validation_detectionDataset = DetectionDataset(validation_complete_df,tokenizer)\n",
    "test_detectionDataset = DetectionDataset(test_original_df,tokenizer, train = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:47.930336Z",
     "start_time": "2023-11-29T12:15:47.920103Z"
    }
   },
   "id": "251efd8d0435def9"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_detectionDataset, batch_size=32, shuffle=True, collate_fn=train_detectionDataset.collate)\n",
    "validation_dataloader = DataLoader(validation_detectionDataset, batch_size=32, shuffle=True, collate_fn=validation_detectionDataset.collate)\n",
    "test_dataloader = DataLoader(test_detectionDataset, batch_size=len(test_detectionDataset), shuffle=False, collate_fn=test_detectionDataset.test_collate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:48.531616Z",
     "start_time": "2023-11-29T12:15:48.526580Z"
    }
   },
   "id": "6c03ad8ebbb485ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "143a9909d49009dd"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# source : https://d2l.ai/chapter_attention-mechanisms-and-transformers/multihead-attention.html\n",
    "class PositionalEncoding(nn.Module):  #@save\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=3000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:49.884326Z",
     "start_time": "2023-11-29T12:15:49.876779Z"
    }
   },
   "id": "5cc96eb36ea7c617"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,n_layers = 6,nhead = 4,dim_feedforward = 512,dropout = 0.5,activation = \"gelu\"):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.position_encoding = PositionalEncoding(embedding_size,dropout)\n",
    "        self.Encoder = nn.TransformerEncoderLayer(\n",
    "            d_model = embedding_size,\n",
    "            nhead = nhead,\n",
    "            dim_feedforward= dim_feedforward,\n",
    "            dropout = dropout,\n",
    "            activation = activation,\n",
    "            batch_first= True,\n",
    "            norm_first= True,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.Encoder, num_layers=n_layers)\n",
    "        self.output = nn.Linear(embedding_size,1,bias = True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x) # B x T X C\n",
    "        x = self.position_encoding(x) # B x T x C with position information added \n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:50.644074Z",
     "start_time": "2023-11-29T12:15:50.636769Z"
    }
   },
   "id": "a36c41bffbb4a890"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(len(tokenizer.get_vocab()),300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:52.911626Z",
     "start_time": "2023-11-29T12:15:52.363477Z"
    }
   },
   "id": "46025c18aea17ace"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def train_batch(X,y,model,loss_function,optimizer):\n",
    "    \"\"\"\n",
    "    :return: (loss , accuracy)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    predicitons = model(X) # Batch * Time stamp * 1\n",
    "    predicitons = torch.mean(predicitons,1).squeeze()\n",
    "    batch_loss = loss_function(predicitons,y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item() * X.shape[0],accuray(y,predicitons)\n",
    "\n",
    "class BestModelSaveCallback:\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.best_accuracy = -1\n",
    "\n",
    "    def __call__(self, accuracy,model):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            model.to(device = \"cpu\")\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            model.to(device=DEVICE)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def Inference(X,y,model,loss_function):\n",
    "    model.eval()\n",
    "    predictions = model(X)\n",
    "    predictions = torch.mean(predictions,1).squeeze()\n",
    "    loss = loss_function(predictions,y)\n",
    "    accuracy = torch.sum((predictions >= 0.5).int() == y)\n",
    "    return loss.item() * X.shape[0],accuracy.item()\n",
    "\n",
    "def computeConfusionMatrix(model,validationLoader):\n",
    "    model.eval()\n",
    "    ground_truth,predictions = [],[]\n",
    "    for batch in validationLoader:\n",
    "\n",
    "        x,y = batch[\"text\"],batch[\"score\"]\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "        prediction = torch.mean(prediction,1).squeeze()\n",
    "        prediction = (prediction >= 0.5).int()\n",
    "        ground_truth.extend((y.detach().cpu().numpy().tolist()))\n",
    "        predictions.extend((prediction.detach().cpu().numpy().tolist()))\n",
    "        break\n",
    "    return ground_truth,predictions\n",
    "\n",
    "\n",
    "def Plot(model,validationLoader,path=\"\"):\n",
    "\n",
    "    ground_truth,predictions = computeConfusionMatrix(model,validationLoader)\n",
    "    cm = confusion_matrix(ground_truth, predictions)\n",
    "    labels = [\"Humans\",\"AI\"]\n",
    "\n",
    "    # Create a heatmap of the confusion matrix\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(os.path.join(path,\"ConfusionMatrix.png\"))\n",
    "    wandb.log({\"Confusion Matrix\": plt})\n",
    "    \n",
    "\n",
    "def train(train_loader,test_loader,model,loss_function,optimizer,best_model_callback):\n",
    "    \"\"\"\n",
    "    :return: (plot nothing to return )\n",
    "    \"\"\"\n",
    "    wandb.watch(model,loss_function,log = \"all\",log_freq=50)\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    with tqdm(total=EPOCHS, desc='Training') as epoch_bar:\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss_epoch,train_accuracy_epoch = [],[]\n",
    "            test_loss_epoch, test_accuracy_epoch = [],[]\n",
    "            for batch in train_loader:\n",
    "                X = batch[\"text\"].to(DEVICE)\n",
    "                y = batch[\"score\"].to(DEVICE)\n",
    "                loss,accuray = train_batch(X,y,model,loss_function,optimizer)\n",
    "                train_loss_epoch.append(loss)\n",
    "                train_accuracy_epoch.append(accuray)\n",
    "                wandb.log({\"Training Batch Loss\":loss})\n",
    "                wandb.log({\"Training Batch Accuracy\" : accuray})\n",
    "                \n",
    "                #TODO : Remove\n",
    "                break\n",
    "                #TODO : Remove\n",
    "                \n",
    "\n",
    "\n",
    "            for batch in test_loader:\n",
    "                X = batch[\"text\"]\n",
    "                y = batch[\"score\"]\n",
    "                loss,accuray = Inference(X,y,model,loss_function)\n",
    "                test_loss_epoch.append(loss)\n",
    "                test_accuracy_epoch.append(accuray)\n",
    "                \n",
    "                wandb.log({\"Validation Batch Loss\":loss})\n",
    "                wandb.log({\"Validation Batch Accuracy\" : accuray})\n",
    "\n",
    "                #TODO : Remove\n",
    "                break\n",
    "                #TODO : Remove\n",
    "\n",
    "            best_model_callback(np.sum(np.array(test_accuracy_epoch))/len(test_loader.dataset),model)\n",
    "\n",
    "            train_losses.append(np.sum(np.array(train_loss_epoch)) / len(train_loader.dataset)  )\n",
    "            train_accuracies.append(np.sum(np.array(train_accuracy_epoch)) / len(train_loader.dataset) )\n",
    "            test_losses.append(np.sum(np.array(test_loss_epoch))/ len(test_loader.dataset) )\n",
    "            test_accuracies.append(np.sum(np.array(test_accuracy_epoch)) / len(test_loader.dataset) )\n",
    "\n",
    "            epoch_bar.set_postfix(\n",
    "                loss=f'{np.sum(np.array(train_loss_epoch)) / len(train_loader.dataset):.4f}',\n",
    "                accuracy=f'{100 * np.sum(np.array(train_accuracy_epoch)) / len(train_loader.dataset):.2f}%'\n",
    "            )\n",
    "            epoch_bar.set_description(f'Epoch {epoch + 1}')\n",
    "            epoch_bar.update(1)\n",
    "    \n",
    "    # Plot(model,test_loader)\n",
    "    \n",
    "\n",
    "def accuray(y_true,y_predictions):\n",
    "    \"\"\"\n",
    "    :return: accuracy\n",
    "    \"\"\"\n",
    "    final_predicitons = (y_predictions >= 0.5).int()\n",
    "    total_accuracy = torch.sum(y_true == final_predicitons)\n",
    "    return total_accuracy.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:22:03.731487Z",
     "start_time": "2023-11-29T12:22:03.709798Z"
    }
   },
   "id": "7fcf548fab871cf"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(len(tokenizer.get_vocab()),300).to(DEVICE)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "best_model_callback = BestModelSaveCallback(save_path=os.path.join('best_model.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:22:05.098686Z",
     "start_time": "2023-11-29T12:22:04.596309Z"
    }
   },
   "id": "edea7fba9eedd695"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:18<00:00, 18.58s/it, accuracy=0.05%, loss=0.0042]\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader,validation_dataloader,model,loss_function,optimizer,best_model_callback)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:22:29.659856Z",
     "start_time": "2023-11-29T12:22:11.055968Z"
    }
   },
   "id": "35aeefe31755ffd8"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training Batch Accuracy</td><td>▁</td></tr><tr><td>Training Batch Loss</td><td>▁</td></tr><tr><td>Validation Batch Accuracy</td><td>▁</td></tr><tr><td>Validation Batch Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training Batch Accuracy</td><td>3</td></tr><tr><td>Training Batch Loss</td><td>25.70443</td></tr><tr><td>Validation Batch Accuracy</td><td>23</td></tr><tr><td>Validation Batch Loss</td><td>203.95645</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">sunny-snow-4</strong> at: <a href='https://wandb.ai/firs/FinalProjectSYDE599/runs/d1ywl8zl' target=\"_blank\">https://wandb.ai/firs/FinalProjectSYDE599/runs/d1ywl8zl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231129_071528-d1ywl8zl/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:22:37.255909Z",
     "start_time": "2023-11-29T12:22:29.664451Z"
    }
   },
   "id": "b7e4667e98c6f811"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
