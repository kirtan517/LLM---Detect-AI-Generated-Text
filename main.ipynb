{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:35:53.578603Z",
     "start_time": "2023-11-29T06:35:53.567960Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:34:04.948281Z",
     "start_time": "2023-11-29T06:34:04.938352Z"
    }
   },
   "id": "369c10e0a806ed9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Directories of the dataset \n",
    "train_original_directory = os.path.join(\"Data\",\"Original_data\",\"train_essays.csv\")\n",
    "test_original_directory = os.path.join(\"Data\",\"Original_data\",\"test_essays.csv\")\n",
    "train_original_prompts_directory = os.path.join(\"Data\",\"Original_data\",\"train_prompts.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:56.462957Z",
     "start_time": "2023-11-29T06:26:56.460511Z"
    }
   },
   "id": "8fedbfa28d2fc8d0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_original_df = pd.read_csv(train_original_directory)\n",
    "test_original_df = pd.read_csv(test_original_directory)\n",
    "train_original_prompts_df = pd.read_csv(train_original_prompts_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:56.500291Z",
     "start_time": "2023-11-29T06:26:56.463475Z"
    }
   },
   "id": "bdd3d95a8ed5dc10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba0b400657e5dc3a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         id  prompt_id                                               text  \\\n0  0059830c          0  Cars. Cars have been around since they became ...   \n1  005db917          0  Transportation is a large necessity in most co...   \n2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n3  00940276          0  How often do you ride in a car? Do you drive a...   \n4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n\n   generated  \n0          0  \n1          0  \n2          0  \n3          0  \n4          0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated -> 0 means written by humans \n",
    "train_original_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:56.513842Z",
     "start_time": "2023-11-29T06:26:56.502601Z"
    }
   },
   "id": "40147f8929ad1d0e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Data Cleaning should be independent from the dataLoader (Usefull if we plan to use machine learning model as well\n",
    "# Embedding should be injected into the dataloader class (Makes embedding indepent from the dataloading part \n",
    "# At the moment we don't care about the prompt text but might be usefull in future processing "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:56.514276Z",
     "start_time": "2023-11-29T06:26:56.508006Z"
    }
   },
   "id": "9fd429f46234c237"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "    \"\"\"\n",
    "    This class is just to clean the dataset and the output of this class should be a cleaned dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,values:list = None):\n",
    "        self.__paths : list[str] = []\n",
    "        \n",
    "        if values:\n",
    "            self.__paths = [*values]\n",
    "        \n",
    "    @property\n",
    "    def paths(self):\n",
    "        return self.paths\n",
    "    \n",
    "    @paths.setter\n",
    "    def paths(self,value):\n",
    "        self.paths.append(value)\n",
    "        \n",
    "    def clean(self):\n",
    "        final_df = None\n",
    "        for path in self.paths:\n",
    "            temp_df = pd.read_csv(path)\n",
    "            if(path.split('/') == \"Original\"):\n",
    "                temp_df = self.cleanOriginal(temp_df)\n",
    "            \n",
    "            if final_df is None:\n",
    "                final_df = temp_df\n",
    "            else:\n",
    "                final_df = pd.concat([final_df,temp_df])\n",
    "            \n",
    "    def cleanOriginal(self,temp_df):\n",
    "        # TODO: Drop the promptId and Id\n",
    "        return temp_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:56.517875Z",
     "start_time": "2023-11-29T06:26:56.512496Z"
    }
   },
   "id": "94ab24a2c1fc3f62"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "temp = CreateDataset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:56.519264Z",
     "start_time": "2023-11-29T06:26:56.514790Z"
    }
   },
   "id": "e6d499bec1b8c4e8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_final_df = train_original_df[[\"text\",\"generated\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:56.599147Z",
     "start_time": "2023-11-29T06:26:56.577256Z"
    }
   },
   "id": "838110d584229b6b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  generated\n0     Cars. Cars have been around since they became ...          0\n1     Transportation is a large necessity in most co...          0\n2     \"America's love affair with it's vehicles seem...          0\n3     How often do you ride in a car? Do you drive a...          0\n4     Cars are a wonderful thing. They are perhaps o...          0\n...                                                 ...        ...\n1373  There has been a fuss about the Elector Colleg...          0\n1374  Limiting car usage has many advantages. Such a...          0\n1375  There's a new trend that has been developing f...          0\n1376  As we all know cars are a big part of our soci...          0\n1377  Cars have been around since the 1800's and hav...          0\n\n[1378 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1373</th>\n      <td>There has been a fuss about the Elector Colleg...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>Limiting car usage has many advantages. Such a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1375</th>\n      <td>There's a new trend that has been developing f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1376</th>\n      <td>As we all know cars are a big part of our soci...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1377</th>\n      <td>Cars have been around since the 1800's and hav...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1378 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:56.902877Z",
     "start_time": "2023-11-29T06:26:56.899792Z"
    }
   },
   "id": "9e8521b8b50a0324"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/deberta-v3-xsmall\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:58.031956Z",
     "start_time": "2023-11-29T06:26:57.225471Z"
    }
   },
   "id": "cdc6769119fdb705"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "128001"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:58.093936Z",
     "start_time": "2023-11-29T06:26:58.065909Z"
    }
   },
   "id": "c7ec72e3c7665a5b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 11673,\n 260,\n 11673,\n 286,\n 331,\n 441,\n 515,\n 306,\n 1181,\n 2167,\n 267,\n 262,\n 11537,\n 268,\n 261,\n 335,\n 4166,\n 3692,\n 994,\n 263,\n 1119,\n 262,\n 362,\n 4848,\n 1193,\n 260,\n 11673,\n 286,\n 1313,\n 266,\n 852,\n 985,\n 267,\n 316,\n 469,\n 406,\n 1131,\n 515,\n 393,\n 260,\n 420,\n 394,\n 261,\n 355,\n 281,\n 1392,\n 264,\n 900,\n 337,\n 9781,\n 640,\n 4119,\n 338,\n 282,\n 266,\n 397,\n 576,\n 260,\n 502,\n 351,\n 261,\n 9781,\n 262,\n 380,\n 265,\n 2020,\n 520,\n 282,\n 266,\n 397,\n 576,\n 264,\n 333,\n 260,\n 344,\n 334,\n 912,\n 265,\n 291,\n 261,\n 1030,\n 261,\n 307,\n 2514,\n 2324,\n 97689,\n 261,\n 1982,\n 23905,\n 589,\n 4031,\n 11673,\n 261,\n 309,\n 293,\n 4859,\n 44077,\n 1603,\n 261,\n 361,\n 19835,\n 281,\n 262,\n 107550,\n 265,\n 13550,\n 261,\n 399,\n 1686,\n 938,\n 1549,\n 292,\n 814,\n 9458,\n 289,\n 2460,\n 2670,\n 264,\n 365,\n 308,\n 2002,\n 260,\n 11632,\n 504,\n 361,\n 291,\n 269,\n 266,\n 1288,\n 48368,\n 264,\n 763,\n 1827,\n 264,\n 1684,\n 10326,\n 1698,\n 5685,\n 292,\n 97646,\n 260,\n 28223,\n 2020,\n 281,\n 1744,\n 270,\n 621,\n 864,\n 265,\n 10326,\n 1698,\n 5685,\n 267,\n 1611,\n 260,\n 260,\n 260,\n 715,\n 322,\n 264,\n 960,\n 864,\n 267,\n 347,\n 640,\n 25676,\n 893,\n 267,\n 262,\n 780,\n 1017,\n 260,\n 11673,\n 281,\n 262,\n 872,\n 919,\n 270,\n 262,\n 10326,\n 1698,\n 5685,\n 401,\n 265,\n 266,\n 509,\n 265,\n 355,\n 1785,\n 349,\n 441,\n 305,\n 262,\n 326,\n 646,\n 399,\n 306,\n 389,\n 264,\n 424,\n 260,\n 6219,\n 261,\n 307,\n 37486,\n 24264,\n 1785,\n 775,\n 264,\n 38499,\n 261,\n 309,\n 293,\n 2519,\n 32982,\n 649,\n 652,\n 261,\n 361,\n 3045,\n 261,\n 385,\n 538,\n 265,\n 941,\n 24335,\n 6435,\n 261,\n 15893,\n 266,\n 7245,\n 1785,\n 4797,\n 264,\n 913,\n 262,\n 925,\n 265,\n 262,\n 1307,\n 707,\n 260,\n 325,\n 327,\n 652,\n 261,\n 361,\n 277,\n 1420,\n 261,\n 31889,\n 275,\n 402,\n 45972,\n 2989,\n 6154,\n 332,\n 3233,\n 264,\n 1021,\n 308,\n 2020,\n 288,\n 425,\n 289,\n 282,\n 18855,\n 266,\n 1460,\n 53273,\n 1399,\n 1947,\n 260,\n 279,\n 454,\n 556,\n 338,\n 282,\n 2312,\n 264,\n 5075,\n 45972,\n 6154,\n 262,\n 776,\n 406,\n 260,\n 11673,\n 281,\n 262,\n 919,\n 270,\n 36744,\n 1128,\n 2350,\n 334,\n 3045,\n 260,\n 329,\n 1057,\n 361,\n 966,\n 2020,\n 295,\n 282,\n 401,\n 261,\n 265,\n 305,\n 262,\n 6435,\n 272,\n 306,\n 295,\n 1138,\n 264,\n 299,\n 1128,\n 707,\n 260,\n 11927,\n 261,\n 267,\n 262,\n 1030,\n 261,\n 307,\n 15542,\n 2103,\n 406,\n 269,\n 10852,\n 352,\n 266,\n 610,\n 1139,\n 267,\n 57656,\n 261,\n 309,\n 293,\n 3812,\n 20377,\n 8612,\n 652,\n 261,\n 361,\n 1309,\n 272,\n 280,\n 268,\n 487,\n 264,\n 2443,\n 264,\n 340,\n 1226,\n 261,\n 3543,\n 265,\n 58573,\n 268,\n 31075,\n 261,\n 2772,\n 407,\n 261,\n 61395,\n 261,\n 289,\n 681,\n 262,\n 2444,\n 264,\n 374,\n 482,\n 266,\n 640,\n 2103,\n 406,\n 261,\n 2042,\n 3575,\n 265,\n 291,\n 1909,\n 707,\n 50627,\n 22014,\n 265,\n 1915,\n 25166,\n 260,\n 325,\n 284,\n 262,\n 883,\n 1858,\n 395,\n 2020,\n 286,\n 331,\n 7648,\n 275,\n 364,\n 8369,\n 263,\n 26860,\n 6117,\n 270,\n 262,\n 1286,\n 4031,\n 11673,\n 267,\n 262,\n 1909,\n 707,\n 265,\n 574,\n 705,\n 260,\n 1792,\n 334,\n 262,\n 781,\n 265,\n 591,\n 640,\n 2103,\n 538,\n 401,\n 261,\n 278,\n 1279,\n 349,\n 264,\n 4178,\n 262,\n 6435,\n 272,\n 2020,\n 552,\n 321,\n 265,\n 308,\n 9702,\n 292,\n 355,\n 1785,\n 305,\n 262,\n 326,\n 260,\n 279,\n 1030,\n 327,\n 2920,\n 361,\n 5868,\n 263,\n 1948,\n 4517,\n 286,\n 25747,\n 407,\n 1075,\n 262,\n 707,\n 16916,\n 261,\n 41848,\n 23191,\n 286,\n 331,\n 3473,\n 293,\n 3658,\n 261,\n 2937,\n 23191,\n 6049,\n 4821,\n 5382,\n 286,\n 7603,\n 1174,\n 1915,\n 263,\n 353,\n 3097,\n 263,\n 17954,\n 2017,\n 7226,\n 286,\n 26767,\n 322,\n 260,\n 3014,\n 363,\n 2020,\n 303,\n 331,\n 397,\n 270,\n 262,\n 658,\n 265,\n 4877,\n 401,\n 261,\n 278,\n 303,\n 19522,\n 349,\n 264,\n 2211,\n 479,\n 272,\n 286,\n 858,\n 5334,\n 270,\n 266,\n 455,\n 326,\n 261,\n 1915,\n 25166,\n 286,\n 1699,\n 444,\n 261,\n 263,\n 3097,\n 263,\n 2017,\n 7226,\n 286,\n 12895,\n 322,\n 261,\n 305,\n 775,\n 264,\n 262,\n 713,\n 265,\n 591,\n 625,\n 2020,\n 441,\n 260,\n 344,\n 4533,\n 261,\n 262,\n 380,\n 265,\n 625,\n 2020,\n 263,\n 591,\n 640,\n 2103,\n 538,\n 261,\n 286,\n 330,\n 266,\n 610,\n 1239,\n 277,\n 262,\n 1192,\n 265,\n 2350,\n 401,\n 261,\n 278,\n 269,\n 2947,\n 444,\n 262,\n 925,\n 6435,\n 272,\n 262,\n 2020,\n 286,\n 55899,\n 28612,\n 261,\n 278,\n 303,\n 19522,\n 1226,\n 334,\n 4877,\n 264,\n 2211,\n 23191,\n 261,\n 263,\n 1174,\n 444,\n 1915,\n 25166,\n 260,\n 79853,\n 262,\n 380,\n 265,\n 2020,\n 338,\n 282,\n 266,\n 397,\n 576,\n 270,\n 1121,\n 260,\n 471,\n 301,\n 403,\n 2642,\n 262,\n 380,\n 265,\n 2020,\n 293,\n 1461,\n 4289,\n 266,\n 2772,\n 261,\n 289,\n 1461,\n 2220,\n 3398,\n 272,\n 928,\n 280,\n 297,\n 272,\n 659,\n 292,\n 274,\n 263,\n 702,\n 280,\n 297,\n 389,\n 262,\n 380,\n 265,\n 266,\n 640,\n 264,\n 350,\n 274,\n 343,\n 260,\n 502,\n 351,\n 261,\n 9781,\n 262,\n 380,\n 265,\n 2020,\n 520,\n 282,\n 266,\n 397,\n 576,\n 264,\n 333,\n 260,\n 2]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_final_df.iloc[0][\"text\"])[\"input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:58.822955Z",
     "start_time": "2023-11-29T06:26:58.813611Z"
    }
   },
   "id": "b994ac7333622ed6"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "547"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(train_final_df.iloc[1][\"text\"])[\"input_ids\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:59.091330Z",
     "start_time": "2023-11-29T06:26:59.083804Z"
    }
   },
   "id": "8b99464159cdd758"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "3289"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_final_df.iloc[0][\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:59.369981Z",
     "start_time": "2023-11-29T06:26:59.367194Z"
    }
   },
   "id": "2a6040cbf89e820f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "2738"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_final_df.iloc[1][\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:59.582960Z",
     "start_time": "2023-11-29T06:26:59.580256Z"
    }
   },
   "id": "2cb9ad8dbcb31edb"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.pad_token)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:26:59.956863Z",
     "start_time": "2023-11-29T06:26:59.954343Z"
    }
   },
   "id": "23bfdf67c0c39d2"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Create a DataLoader class \n",
    "class DetectionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,Tokenizer = None,train = True,max_length = 100):\n",
    "        self.tokenizer = Tokenizer\n",
    "        self.train = train\n",
    "        self.df = df\n",
    "        self.max_length = max_length\n",
    "        self.padded_token = 0 if self.tokenizer is None else self.tokenizer.convert_tokens_to_ids(self.tokenizer.pad_token)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        :return: text containing the indexes in numpy array / list\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            if self.tokenizer is None: \n",
    "                return {\"text\" : self.df.iloc[item][\"text\"],\"score\" : self.df.iloc[item][\"generated\"]}\n",
    "            else:\n",
    "                vectorized_text = self.vectorize(self.df.iloc[item][\"text\"])\n",
    "                return {\"text\" : vectorized_text,\"score\" : self.df.iloc[item][\"generated\"]}\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def pad(self,vector,length):\n",
    "        result = np.ones(length) * self.padded_token\n",
    "        result[:len(vector)] = vector\n",
    "        return result\n",
    "    \n",
    "    def collate(self,batch):\n",
    "        max_length = max([len(item['text']) for item in batch])\n",
    "        texts = [self.pad(item['text'],max_length) for item in batch]\n",
    "        scores = [item['score'] for item in batch]    \n",
    "        return {'text': torch.LongTensor(texts), \n",
    "                'score': torch.tensor(scores, dtype=torch.float32)}\n",
    "        \n",
    "    \n",
    "    def vectorize(self,text):\n",
    "        return self.tokenizer(text)[\"input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:27:00.332474Z",
     "start_time": "2023-11-29T06:27:00.326233Z"
    }
   },
   "id": "699912aecea29d4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "detectionDataset = DetectionDataset(train_final_df,tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:27:01.023814Z",
     "start_time": "2023-11-29T06:27:01.021209Z"
    }
   },
   "id": "251efd8d0435def9"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(detectionDataset, batch_size=32, shuffle=True, collate_fn=detectionDataset.collate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:27:02.444556Z",
     "start_time": "2023-11-29T06:27:02.440920Z"
    }
   },
   "id": "6c03ad8ebbb485ce"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "128001"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:27:02.867851Z",
     "start_time": "2023-11-29T06:27:02.865676Z"
    }
   },
   "id": "87a6db15e9fc3bfa"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# source : https://d2l.ai/chapter_attention-mechanisms-and-transformers/multihead-attention.html\n",
    "class PositionalEncoding(nn.Module):  #@save\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:27:03.517335Z",
     "start_time": "2023-11-29T06:27:03.515365Z"
    }
   },
   "id": "5cc96eb36ea7c617"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,n_layers = 6,nhead = 4,dim_feedforward = 512,dropout = 0.5,activation = \"gelu\"):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.position_encoding = PositionalEncoding(embedding_size,dropout)\n",
    "        self.Encoder = nn.TransformerEncoderLayer(\n",
    "            d_model = embedding_size,\n",
    "            nhead = nhead,\n",
    "            dim_feedforward= dim_feedforward,\n",
    "            dropout = dropout,\n",
    "            activation = activation,\n",
    "            batch_first= True,\n",
    "            norm_first= True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.Encoder, num_layers=n_layers)\n",
    "        self.output = nn.LazyLinear(1,bias = True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x) # B x T X C\n",
    "        x = self.position_encoding(x) # B x T x C with position information added \n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:30:33.032492Z",
     "start_time": "2023-11-29T06:30:33.019103Z"
    }
   },
   "id": "a36c41bffbb4a890"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/opt/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(len(tokenizer.get_vocab()),300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:30:34.379064Z",
     "start_time": "2023-11-29T06:30:33.936676Z"
    }
   },
   "id": "46025c18aea17ace"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "X = torch.LongTensor(np.ones((10,30)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:30:35.876953Z",
     "start_time": "2023-11-29T06:30:35.874496Z"
    }
   },
   "id": "b91ea91ac5c0f81d"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "result = model(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:30:36.541919Z",
     "start_time": "2023-11-29T06:30:36.506118Z"
    }
   },
   "id": "1d29c7d5d099fd03"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 30, 1])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T06:30:36.985941Z",
     "start_time": "2023-11-29T06:30:36.983361Z"
    }
   },
   "id": "4e8af5d8a05127a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_batch(X,y,model,loss_function,optimizer):\n",
    "    \"\"\"\n",
    "    :return: (loss , accuracy)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    predicitons = model(X)\n",
    "    batch_loss = loss_function(predicitons,y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item() * X.shape[0],accuray(y,predicitons)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def Inference(X,y,model,loss_function):\n",
    "    predictions = model(X)\n",
    "    loss = loss_function(predictions,y)\n",
    "    accuracy = torch.sum(torch.argmax(predictions) == y)\n",
    "    return loss.item() * X.shape[0],accuracy.item()\n",
    "\n",
    "def train(train_loader,test_loader,model,loss_function,optimizer):\n",
    "    \"\"\"\n",
    "    :return: (plot nothing to return )\n",
    "    \"\"\"\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    with tqdm(total=EPOCHS, desc='Training') as epoch_bar:\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss_epoch,train_accuracy_epoch = [],[]\n",
    "            test_loss_epoch, test_accuracy_epoch = [],[]\n",
    "            for X,y in train_loader:\n",
    "                loss,accuray = train_batch(X,y,model,loss_function,optimizer)\n",
    "                train_loss_epoch.append(loss)\n",
    "                train_accuracy_epoch.append(accuray)\n",
    "\n",
    "\n",
    "            for X,y in test_loader:\n",
    "                loss,accuray = Inference(X,y,model,loss_function)\n",
    "                test_loss_epoch.append(loss)\n",
    "                test_accuracy_epoch.append(accuray)\n",
    "\n",
    "            train_losses.append(np.sum(np.array(train_loss_epoch)) / len(train_loader.dataset)  )\n",
    "            train_accuracies.append(np.sum(np.array(train_accuracy_epoch)) / len(train_loader.dataset) )\n",
    "            test_losses.append(np.sum(np.array(test_loss_epoch))/ len(test_loader.dataset) )\n",
    "            test_accuracies.append(np.sum(np.array(test_accuracy_epoch)) / len(test_loader.dataset) )\n",
    "\n",
    "            epoch_bar.set_postfix(\n",
    "                loss=f'{np.sum(np.array(train_loss_epoch)) / len(train_loader.dataset):.4f}',\n",
    "                accuracy=f'{100 * np.sum(np.array(train_accuracy_epoch)) / len(train_loader.dataset):.2f}%'\n",
    "            )\n",
    "            epoch_bar.set_description(f'Epoch {epoch + 1}')\n",
    "            epoch_bar.update(1)\n",
    "    plot(train_losses,train_accuracies,test_losses,test_accuracies)\n",
    "\n",
    "def plot(train_losses,train_accuracies,test_losses,test_accuraies):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss', marker='o')\n",
    "    plt.plot(test_losses, label='Test Loss', marker='o')\n",
    "    plt.title('Training and Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy', marker='o')\n",
    "    plt.plot(test_accuraies, label='Test Accuracy', marker='o')\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "\n",
    "def accuray(y_true,y_predictions):\n",
    "    \"\"\"\n",
    "    :return: accuracy\n",
    "    \"\"\"\n",
    "    final_predicitons = torch.argmax(y_predictions,dim = 1)\n",
    "    total_accuracy = torch.sum(y_true == final_predicitons)\n",
    "    return total_accuracy.item()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fcf548fab871cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Transformer()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edea7fba9eedd695"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(train_loader,test_loader,model,loss_function,optimizer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35aeefe31755ffd8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
